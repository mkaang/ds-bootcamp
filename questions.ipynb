{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Is the mean of distances to a cluster as the same as the distance to the cluster centroid?\n",
    "Let's check it out.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create data\n",
    "x, y = make_blobs(n_samples=100, centers=5, n_features=2, random_state=42, cluster_std=0.5)\n",
    "df = pd.DataFrame(dict(x1=x[:,0], x2=x[:,1], y=y))\n",
    "\n",
    "# define a sample point\n",
    "sample = df.sample(1, random_state=42)\n",
    "\n",
    "# define the cluster\n",
    "label = 4\n",
    "cluster = df[df.y == label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2(x1, x2, y1, y2):\n",
    "    return np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "def l1(x1, x2, y1, y2):\n",
    "    return np.abs(x1 - x2) + np.abs(y1 - y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of distances: 3.26\n",
      "Distance to cluster centroid: 3.23\n"
     ]
    }
   ],
   "source": [
    "summation = 0\n",
    "s_x1 = sample.x1\n",
    "s_x2 = sample.x2\n",
    "for c_x1, c_x2 in zip(cluster.x1, cluster.x2):\n",
    "    summation += l2(c_x1, s_x1, c_x2, s_x2)\n",
    "print(\"Mean of distances: %.2f\" % (summation.item() / cluster.shape[0]))\n",
    "\n",
    "s_x1 = sample.x1\n",
    "s_x2 = sample.x2\n",
    "cm_x1 = cluster.x1.mean()\n",
    "cm_x2 = cluster.x2.mean()\n",
    "summation = 0\n",
    "for x1, x2 in zip(cluster.x1, cluster.x2):\n",
    "    summation += l2(cm_x1, s_x1, cm_x2, s_x2)\n",
    "print(\"Distance to cluster centroid: %.2f\" % (summation.item() / cluster.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that when std is decreasing the these two errors are getting closer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Is test sampling in recommendation matrix is correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.0 82.0\n"
     ]
    }
   ],
   "source": [
    "r = np.array([[7, 6, 7, 4, 5, 4],\n",
    "              [6, 7, np.nan, 4, 3, 4],\n",
    "              [np.nan, 3, 3, 1, 1, np.nan],\n",
    "              [1, 2, 3, 3, 3, 4],\n",
    "              [1, np.nan, 1, 2, 3, 3]])\n",
    "\n",
    "idx = np.random.choice(np.arange(6), 2, replace=False)\n",
    "\n",
    "irow, jcol = np.where(~np.isnan(r))\n",
    "\n",
    "r_copy1 = r.copy()\n",
    "r_copy2 = r.copy()\n",
    "\n",
    "test_irow = irow[idx]\n",
    "test_jcol = jcol[idx]\n",
    "\n",
    "for i in test_irow:\n",
    "    for j in test_jcol:\n",
    "        r_copy1[i][j] = np.nan\n",
    "\n",
    "for (i, j) in zip(test_irow, test_jcol):\n",
    "    r_copy2[i][j] = np.nan\n",
    "\n",
    "print(np.nansum(r_copy1), np.nansum(r_copy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaan/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174331.0 349381.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://files.grouplens.org/datasets/movielens/ml-100k/u.data', delimiter=r'\\t',\n",
    "names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "r = df.pivot(index='user_id', columns='item_id', values='rating').values\n",
    "\n",
    "irow, jcol = np.where(~np.isnan(r))\n",
    "\n",
    "r_copy1 = r.copy()\n",
    "r_copy2 = r.copy()\n",
    "\n",
    "idx = np.random.choice(np.arange(100_000), 1000, replace=False)\n",
    "\n",
    "test_irow = irow[idx]\n",
    "test_jcol = jcol[idx]\n",
    "\n",
    "for i in test_irow:\n",
    "    for j in test_jcol:\n",
    "        r_copy1[i][j] = np.nan\n",
    "\n",
    "for (i, j) in zip(test_irow, test_jcol):\n",
    "    r_copy2[i][j] = np.nan\n",
    "\n",
    "print(np.nansum(r_copy1), np.nansum(r_copy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems correct in small data. But in large data it is not the same thing. Rate is almost twice. The code in the lesson also chooses opposite side of the diagonal."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "593d40d7cffee2f7fc9148203eec6afcc615f6015e795468e82ce0a2cb5c8eb0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
