{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import NormalPredictor, BaselineOnly, SVD, SVDpp, NMF, KNNBasic, KNNBaseline, KNNWithMeans\n",
    "\n",
    "transactions = pd.read_csv('data/transactions.csv', parse_dates=['t_dat'])\n",
    "articles = pd.read_csv('data/articles.csv')\n",
    "customers = pd.read_csv('data/customers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31548013, 5) (240311, 5)\n",
      "(27101148, 3) (213728, 3)\n"
     ]
    }
   ],
   "source": [
    "start_train = datetime.date(2019, 9, 22)\n",
    "start_test = datetime.date(2020, 9, 15)\n",
    "\n",
    "tran_test = transactions[transactions.t_dat > pd.Timestamp(start_test)]\n",
    "tran_train = transactions[(transactions.t_dat <= pd.Timestamp(start_test)) ] # & (transactions.t_dat > pd.Timestamp(start_train))\n",
    "\n",
    "del transactions\n",
    "\n",
    "print(tran_train.shape, tran_test.shape)\n",
    "\n",
    "def group_transactions(df):\n",
    "    df = df.groupby([\"customer_id\", \"article_id\"])['price'].sum()\n",
    "    return df.reset_index()\n",
    "\n",
    "tran_train, tran_test = map(group_transactions, (tran_train, tran_test))\n",
    "\n",
    "print(tran_train.shape, tran_test.shape)\n",
    "\n",
    "def min_max_normalization(df):\n",
    "    df.price = (df.price - df.price.min()) / (df.price.max() - df.price.min())\n",
    "    return df\n",
    "\n",
    "tran_train, tran_test = map(min_max_normalization, (tran_train, tran_test))\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data_train = Dataset.load_from_df(tran_train[[\"customer_id\", \"article_id\", \"price\"]], reader=reader)\n",
    "data_trainset = data_train.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tran_test):\n",
    "\n",
    "    result = []\n",
    "    for idx, row in tqdm(tran_test.iterrows()):\n",
    "        y = row['price']\n",
    "        y_pred = model.predict(row['customer_id'], row['article_id']).est\n",
    "        result.append((y, y_pred))\n",
    "\n",
    "    result = np.array(result)\n",
    "    errs = result[:,0] - result[:,1]\n",
    "    rmse = np.sqrt(np.mean(errs ** 2))\n",
    "    mae = np.mean(np.abs(errs))\n",
    "\n",
    "    print(f\"Score in test set mae: {mae:.3f}, rmse: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(model, item_list: np.ndarray, user: int, top_k: int = 5):\n",
    "    preds = list()\n",
    "    for item in item_list:\n",
    "        pred = model.predict(user, item).est\n",
    "        preds.append(pred)\n",
    "\n",
    "    assert len(item_list) == len(preds)\n",
    "\n",
    "    idxs = np.array(preds).argsort()[::-1][:top_k]\n",
    "\n",
    "    values = np.array(preds)[idxs]\n",
    "    keys = item_list[idxs]\n",
    "\n",
    "    return dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random and Bias Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for NormalPredictor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213728it [00:11, 18945.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in test set mae: 0.022, rmse: 0.034\n",
      "Results for BaselineOnly\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213728it [00:10, 20172.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in test set mae: 0.019, rmse: 0.029\n"
     ]
    }
   ],
   "source": [
    "models = [NormalPredictor(), BaselineOnly()]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    model_to_fit = model\n",
    "    print(f\"Results for {type(model_to_fit).__name__}\")\n",
    "    model.fit(data_trainset)\n",
    "    evaluate(model, tran_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213728it [00:11, 18687.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in test set mae: 0.026, rmse: 0.040\n"
     ]
    }
   ],
   "source": [
    "model_to_fit = SVD()\n",
    "print(f\"Results for {type(model_to_fit).__name__}\")\n",
    "model_to_fit.fit(data_trainset)\n",
    "evaluate(model_to_fit, tran_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNNBasic\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 36.7 GiB for an array with shape (70221, 70221) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2805/4190718621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_to_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNBasic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msim_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Results for {type(model_to_fit).__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_to_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_trainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtran_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/surprise/prediction_algorithms/knns.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, trainset)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mSymmetricAlgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_similarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/surprise/prediction_algorithms/algo_base.py\u001b[0m in \u001b[0;36mcompute_similarities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'verbose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computing the {0} similarity matrix...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruction_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'verbose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done computing similarity matrix.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/surprise/similarities.pyx\u001b[0m in \u001b[0;36msurprise.similarities.cosine\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 36.7 GiB for an array with shape (70221, 70221) and data type float64"
     ]
    }
   ],
   "source": [
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False\n",
    "               }\n",
    "model_to_fit = KNNBasic(sim_options=sim_options)\n",
    "print(f\"Results for {type(model_to_fit).__name__}\")\n",
    "model_to_fit.fit(data_trainset)\n",
    "evaluate(model_to_fit, tran_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x7fa54985d730>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaselineOnly()\n",
    "model.fit(data_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213728it [00:09, 21472.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009625    871\n",
       "0.000000    104\n",
       "0.013802     69\n",
       "0.013417     65\n",
       "0.008626     61\n",
       "           ... \n",
       "0.011141      1\n",
       "0.012057      1\n",
       "0.013454      1\n",
       "0.013766      1\n",
       "0.012086      1\n",
       "Length: 195283, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = list()\n",
    "for idx, row in tqdm(tran_test.iterrows()):\n",
    "    pred = model.predict(row['customer_id'], row['article_id']).est\n",
    "    preds.append(pred)\n",
    "\n",
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_unseen = set(articles.article_id.unique()) - set(tran_train.article_id.unique()) - set(tran_test.article_id.unique())\n",
    "customers_unseen = set(customers.customer_id.unique()) - set(tran_train.customer_id.unique()) - set(tran_test.customer_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='397b134637693dd30bf21efd253fef827682602d9a8571b991dddaa8ad0cafd5', iid=638976001, r_ui=None, est=0.00962524045748534, details={'was_impossible': False})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(list(customers_unseen)[0], list(articles_unseen)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It seems that model can predict even not seen in train set since predicts with overall mean i think.\n",
    "- Hopefully knn-based models predict different than mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{780031001: 0.14738238172775892,\n",
       " 780031004: 0.12462908023721772,\n",
       " 916300002: 0.12141662780409737,\n",
       " 876342001: 0.1075285683908763,\n",
       " 839464001: 0.08702136985695666}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions with seen articles\n",
    "user = tran_test.customer_id.unique()[0]\n",
    "item_list = tran_test.article_id.unique()\n",
    "\n",
    "recommend(model, item_list, user, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2693/942464544.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mitem_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marticle_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Predictions with unseen articles\n",
    "user = tran_test.customer_id.unique()[0]\n",
    "item_list = articles.article_id.unique()\n",
    "\n",
    "recommend(model, item_list, user, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{780031001: 0.1469779500050143,\n",
       " 780031004: 0.12422464851447311,\n",
       " 916300002: 0.12101219608135276,\n",
       " 876342001: 0.10712413666813168,\n",
       " 639338001: 0.10582483459278863}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions with unseen customer\n",
    "user = list(customers_unseen)[0]\n",
    "item_list = articles.article_id.unique()\n",
    "\n",
    "recommend(model, item_list, user, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{780031001: 0.1469779500050143,\n",
       " 780031004: 0.12422464851447311,\n",
       " 916300002: 0.12101219608135276,\n",
       " 876342001: 0.10712413666813168,\n",
       " 639338001: 0.10582483459278863}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions with unseen customer\n",
    "user = list(customers_unseen)[1]\n",
    "item_list = articles.article_id.unique()\n",
    "\n",
    "recommend(model, item_list, user, 5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "593d40d7cffee2f7fc9148203eec6afcc615f6015e795468e82ce0a2cb5c8eb0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
